{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#It works for all the csv's at the same time, although there are some csv's with inaccurate extraction, it will simply output an extra csv containing the paths of those files.\n",
    "#What it does?: It solves header repeatation problem by combining them. Header named with 'municipality' or 'upazilla' or 'thana/upazilla' or 'years' repeats in 2nd row, 3rd row, 4th(sometimes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definition=> this combines the headers and replaces the target-row header;\n",
    "#Parameters=> target-row: is the main header,row_tocheck: is the number of sub-headers need to be combined\n",
    "#Return=> first argument returns the number of header rows that has been checked, it'll be usefull to drop the redundant rows. Second one returns true if there is any csv without datas, otherewise returns false.\n",
    "def combineHeaders(target_row, row_tocheck, data, check_filewithnodata = 0):\n",
    "    target_headers = list()\n",
    "    target_headers = data.iloc[[target_row]]\n",
    "    row_checked = list();\n",
    "    row_ttl, col_ttl = data.shape;\n",
    "    for i in range(row_tocheck):\n",
    "        next_row = target_row + i + 1;\n",
    "        \n",
    "        #Checks if outofbounderror occurs, some files doesn't have any datas so facing outofbounderror, if you want to track those files just add a new parameter filepath and print(filepath) in the if statement\n",
    "        if(next_row > row_ttl - 1):\n",
    "            check_filewithnodata = 1;\n",
    "            return row_checked,check_filewithnodata;\n",
    "        \n",
    "        for col in range(col_ttl):\n",
    "            #FirstIf=> To check wheather the next column is header row or data row, if data row than no need to go further\n",
    "            if((col==1) and (target_headers.iloc[0,col]!=data.iloc[next_row,col])):\n",
    "                #print('Data row:',next_row)\n",
    "                return row_checked,check_filewithnodata;\n",
    "            if ((col!=0) and (target_headers.iloc[0,col]!=data.iloc[next_row,col])): # ignore column 0\n",
    "                \n",
    "                # update\n",
    "                data.iloc[target_row,col] = str(data.iloc[target_row,col]) + ' ' + str(data.iloc[next_row,col])\n",
    "        #print('Header Rows: ',next_row)\n",
    "        row_checked = row_checked + [next_row]\n",
    "    return row_checked, check_filewithnodata;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "originpath = \"cleaned_CSVs/\"\n",
    "destpath = \"cleaned_CSVs_headerscombined/\"\n",
    "districtList = os.listdir(originpath)#making a list of all the districts\n",
    "filenameList_nodata = list();#list of files without datas\n",
    "for districtname in districtList:\n",
    "    filenameList = [filename for filename in os.listdir(originpath + districtname) if filename.endswith('.csv')]\n",
    "    for filename in filenameList:\n",
    "        filepath = originpath + districtname + \"/\" + filename;\n",
    "    #         print(filepath);\n",
    "        original_data = pd.read_csv(filepath)\n",
    "        row_checked, check_filewithnodata = combineHeaders(2,2,original_data)\n",
    "        \n",
    "        #check csv's without any data\n",
    "        if check_filewithnodata:\n",
    "            filenameList_nodata = filenameList_nodata + [filepath]\n",
    "            \n",
    "        # drop redundant rows\n",
    "        if row_checked:\n",
    "            for row in row_checked:\n",
    "                original_data.drop([row], axis=0, inplace=True)\n",
    "        # drop one extra column\n",
    "        original_data.drop(original_data.columns[0], axis=1, inplace=True)\n",
    "\n",
    "        # reset the index after dropping rows\n",
    "        original_data = original_data.reset_index(drop=True)\n",
    "\n",
    "        filepath_parent = destpath + districtname\n",
    "        os.makedirs(filepath_parent, exist_ok=True)\n",
    "        filepath = filepath_parent + \"/\" + filename\n",
    "        original_data.to_csv(filepath, index = True)\n",
    "\n",
    "with open(destpath + \"filenamelist_without_data.txt\", 'w') as f:\n",
    "    for filename in filenameList_nodata:\n",
    "        f.write(\"%s\\n\" % filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
